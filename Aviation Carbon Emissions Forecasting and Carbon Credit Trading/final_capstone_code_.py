# -*- coding: utf-8 -*-
"""Final Capstone Code .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q5gsPL8DvbOVZ6PbxeA2Cj51jfzqFwv-
"""

!pip uninstall torch -y
!pip install torch --no-cache-dir

import requests #For API Data Extraction
import pandas as pd
import numpy as np
import tensorflow as tf
import torch
import matplotlib.pyplot as plt
import seaborn as sns

#Packages for Model Building
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.tsa.arima.model import ARIMA
import gym #For RL Agent
import random
import math

import requests
import time
from requests.auth import HTTPBasicAuth

!pip install geopy

from geopy.distance import geodesic

from google.colab import files
airports=files.upload() #Importing Airline Dataset to match Nearest Airport as Destination for each flight

filename = list(airports.keys())[0]
airports_df = pd.read_csv(filename)

airports_df=airports_df.drop(columns=['ident','type','elevation_ft','continent','iso_country','iso_region','municipality','iata_code','gps_code','local_code'])

airports_df.dropna(subset=['icao_code'], inplace=True)
airports_df= airports_df[airports_df['icao_code'].str.strip() != '']

airports_df[['latitude', 'longitude']] = airports_df['coordinates'].str.split(',', expand=True)
airports_df['latitude'] = airports_df['latitude'].astype(float)
airports_df['longitude'] = airports_df['longitude'].astype(float)
airports_df = airports_df.drop(columns=['coordinates'])

airports_df.info()

def get_current_flight_data(limit=500):
    url = "https://opensky-network.org/api/states/all"
    response = requests.get(url).json()

    flights = []
    for flight in response.get("states", [])[:limit]:
        flights.append({
            "icao24": flight[0],
            "callsign": flight[1],
            "longitude": flight[5],
            "latitude": flight[6],
            "altitude": flight[7],
            "velocity": flight[9]
        })

    return pd.DataFrame(flights)
#Creating Flight Path Details from OpenSky API

current_df=get_current_flight_data()

print(current_df.head())

#Fetching Weather Data for Flight Location/Emissions

def get_weather_data(lat, lon):
    API_KEY = "31064343371639e81a81a13bae7fcb9a"
    URL = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={API_KEY}&units=metric"
    try:
        response = requests.get(URL).json()
        print(response)
        return {
            "temperature": response.get("main", {}).get("temp", np.nan),
            "wind_speed": response.get("wind", {}).get("speed", np.nan),
            "humidity": response.get("main", {}).get("humidity", np.nan)
        }
    except Exception as e:
        print(f"Error: {e}")
        return {"temperature": np.nan, "wind_speed": np.nan, "humidity": np.nan}
#Emissions are impacted by Weather of Longitude, Latitude of flight



def prepare_dataset(flights_df, airports_df):
    from math import radians, sin, cos, sqrt, atan2
    import pandas as pd

    # Haversine distance formula to calculate distance
    def haversine(lat1, lon1, lat2, lon2):
        R = 6371
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
        c = 2 * atan2(sqrt(a), sqrt(1 - a))
        return R * c

    if "destination" in flights_df.columns:
        flights_df['destination'] = flights_df['destination'].astype(str).str.strip()

    # Find nearest airport for each flight and assume as destination
    def find_nearest_airport(row):
        if pd.isna(row['latitude']) or pd.isna(row['longitude']):
            return pd.Series([None, None, None, None])
        lat1, lon1 = row['latitude'], row['longitude']
        airports_df['distance_km'] = airports_df.apply(
            lambda ap: haversine(lat1, lon1, ap['latitude'], ap['longitude']), axis=1
        )
        nearest = airports_df.loc[airports_df['distance_km'].idxmin()]
        return pd.Series([
            nearest['icao_code'],
            nearest['name'],
            nearest['latitude'],
            nearest['longitude']
        ])

    flights_df[['nearest_airport_icao', 'nearest_airport_name', 'airport_lat', 'airport_lon']] = flights_df.apply(
        find_nearest_airport, axis=1
    )

    # Compute distance to distance
    flights_df["distance_km"] = flights_df.apply(
        lambda row: haversine(row["latitude"], row["longitude"], row["airport_lat"], row["airport_lon"]),
        axis=1
    )

    # Adding weather data per flight
    flights_df["weather"] = flights_df.apply(
        lambda row: get_weather_data(row["latitude"], row["longitude"]), axis=1
    )

    weather_df = pd.json_normalize(flights_df["weather"])
    flights_df = pd.concat([flights_df.drop(columns=["weather"]), weather_df], axis=1)

    flights_df.dropna(inplace=True)

    return flights_df
#Preparing Final Dataset to train model for emissions calculation and prediction

#Using ARIMA to Forecast Carbon Credit Price
def get_dynamic_carbon_price(history_series):
    model = ARIMA(history_series, order=(2, 1, 2))
    model_fit = model.fit()
    forecast = model_fit.forecast(steps=1).iloc[0]
    return float(forecast)


# Compute Emissions
def compute_carbon_emissions(df, carbon_price):
    df["burn_rate"] = 0.02 * df["velocity"]
    df["fuel_burn_kg"] = df["distance_km"] * df["burn_rate"]
    df["emissions_kg"] = df["fuel_burn_kg"] * 3.16  # Jet fuel CO2 factor
    df["credits_needed"] = df["emissions_kg"] / 1000  # 1 credit = 1 tonne
    df["credit_cost_usd"] = df["credits_needed"] * carbon_price
    return df

flight_data = prepare_dataset(current_df,airports_df)



price_history = pd.Series([70 + np.sin(i/3) * 5 + np.random.randn() for i in range(100)])
carbon_price = get_dynamic_carbon_price(price_history)
print(f" Predicted Carbon Price: ${carbon_price:.2f}")
#Using a random series as historical carbon price data due to restrictions in API
flight_data = compute_carbon_emissions(flight_data, carbon_price)

sample_df = flight_data[['icao24', 'callsign', 'longitude', 'latitude', 'altitude',
                         'velocity', 'distance_km', 'temperature', 'wind_speed',
                         'humidity', 'burn_rate','fuel_burn_kg', 'credits_needed', 'credit_cost_usd','emissions_kg']].head(5)

sample_df = sample_df.round(2)

fig, ax = plt.subplots(figsize=(20, 3))  # Increase width
ax.axis('tight')
ax.axis('off')

table = ax.table(cellText=sample_df.values,
                 colLabels=sample_df.columns,
                 cellLoc='center',
                 colLoc='center',
                 loc='center')

table.scale(1.2, 1.2)
table.auto_set_font_size(False)
table.set_fontsize(10)
plt.show()

print(flight_data.head())

print(flight_data['distance_km'].nlargest(10))

flight_data = flight_data.sort_values(by="callsign")

#Scaling and Preprocessing Data for Emission Prediction Model
features = ['altitude', 'velocity', 'temperature', 'wind_speed', 'humidity', 'distance_km']
target = 'emissions_kg'

scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(flight_data[features])
scaled_target = scaler.fit_transform(flight_data[[target]])

X = []
y = []

n_steps = 3
for i in range(n_steps, len(scaled_features)):
    X.append(scaled_features[i - n_steps:i])
    y.append(scaled_target[i])

X = np.array(X)
y = np.array(y)

len(X),len(y)

def build_lstm_model(input_shape):
    model = Sequential([
        Input(shape=input_shape),
        LSTM(128, return_sequences=True, recurrent_dropout=0.2),
        Dropout(0.3),
        LSTM(64, return_sequences=False, recurrent_dropout=0.2),
        BatchNormalization(),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')
    return model

#GRU Model for Emissions Prediction
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout, Input

def build_gru_model(input_shape):
    model = Sequential([
        Input(shape=input_shape),
        GRU(128, return_sequences=True, recurrent_dropout=0.2),
        Dropout(0.3),
        GRU(64, return_sequences=False, recurrent_dropout=0.2),
        BatchNormalization(),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])

    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')
    return model

from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Flatten

def build_convlstm_model(timesteps, features):
    model = Sequential([
        ConvLSTM2D(
            filters=64,
            kernel_size=(1, 3),
            activation='relu',
            padding='same',
            return_sequences=True,
            input_shape=(timesteps, 1, features, 1)
        ),
        BatchNormalization(),
        Dropout(0.3),
        ConvLSTM2D(
            filters=32,
            kernel_size=(1, 3),
            activation='relu',
            padding='same',
            return_sequences=False
        ),
        BatchNormalization(),
        Flatten(),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])

    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')
    return model

def train_and_evaluate(model, X_train, y_train, X_test, y_test, name="Model"):
    history = model.fit(X_train, y_train, epochs=800, batch_size=64,
                        validation_split=0.2, verbose=0)

    y_pred = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    print(f"{name} RMSE: {rmse:.4f}")
    print(f"{name} RÂ² Score: {r2:.4f}")

def train_and_evaluate2(model, X, y, name="Model"):
    history = model.fit(X, y, epochs=800, batch_size=64,
                        validation_split=0.2, verbose=0)

    y_pred = model.predict(X)

    rmse = np.sqrt(mean_squared_error(y, y_pred))
    r2 = r2_score(y, y_pred)

    print(f"{name} RMSE: {rmse:.4f}")
    print(f"{name} RÂ² Score: {r2:.4f}")

def plot_emission_predictions(model, X, flight_data, features, target, scaler, n_steps, title="Actual vs Predicted Carbon Emissions"):

    predicted = model.predict(X)

    padded = np.concatenate([np.zeros((len(predicted), len(features))), predicted], axis=1)
    predicted = scaler.inverse_transform(np.concatenate([np.zeros((len(predicted), len(features))), predicted], axis=1))[:, -1]

    actual = flight_data[target].values[n_steps:]

    plt.figure(figsize=(12, 5))
    plt.plot(actual, label="Actual")
    plt.plot(predicted, label="Predicted")
    plt.title(title)
    plt.xlabel("Flight Index")
    plt.ylabel("Carbon Emissions (kg)")
    plt.legend()
    plt.grid(True)
    plt.show()

plt.figure(figsize=(12, 5))
plt.plot(flight_data[target].values[n_steps:], color='black', linewidth=1.5)
plt.title('Original Carbon Emissions')
plt.xlabel('Flight Index')
plt.ylabel('Emissions (kg)')
plt.grid(True)
plt.tight_layout()
plt.show()

from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y.reshape(-1, 1), test_size=0.2, shuffle=False,random_state=42)

# LSTM
lstm_model = build_lstm_model(X.shape[1:])
#lstmhistory=train_and_evaluate(lstm_model, X_train, y_train, X_test, y_test, name="LSTM")
lstmhistory2=train_and_evaluate2(lstm_model, X, y, name="LSTM")
plot_emission_predictions(model=lstm_model,X=X,flight_data=flight_data,features=features,target=target,scaler=scaler,n_steps=n_steps,title="LSTM - Carbon Emissions Prediction")

# GRU
gru_model = build_gru_model(X.shape[1:])
#gruhistory=train_and_evaluate(gru_model, X_train, y_train, X_test, y_test, name="GRU")
gruhistory2=train_and_evaluate2(lstm_model, X, y, name="GRU")
plot_emission_predictions(model=gru_model,X=X,flight_data=flight_data,features=features,target=target,scaler=scaler,n_steps=n_steps,title="GRU - Carbon Emissions Prediction")

# ConvLSTM (requires 5D input)
X_conv = X.reshape((X.shape[0], X.shape[1], 1, X.shape[2], 1))
Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_conv, y.reshape(-1, 1), test_size=0.2, shuffle=False)
Xc = np.concatenate((Xc_train, Xc_test), axis=0)

conv_model = build_convlstm_model(X.shape[1], X.shape[2])
#convhistory=train_and_evaluate(conv_model, Xc_train, yc_train, Xc_test, yc_test, name="ConvLSTM")
convhistory2=train_and_evaluate2(conv_model, Xc, y, name="ConvLSTM")
plot_emission_predictions(model=conv_model,X=Xc,flight_data=flight_data,features=features,target=target,scaler=scaler,n_steps=n_steps,title="ConvLSTM - Carbon Emissions Prediction")

flight_data.columns

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam


features = ['altitude', 'velocity', 'humidity', 'fuel_burn_kg','distance_km','wind_speed']
target = 'emissions_kg'


scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(flight_data[features])
y = flight_data[target].values

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=True, random_state=42)

model = Sequential()
model.add(Dense(128, input_dim=len(features), activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)

y_pred = model.predict(X_test).flatten()
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"DNN RMSE: {rmse:.4f}")
print(f"DNN RÂ² Score: {r2:.4f}")

y_full_pred = model.predict(X_scaled).flatten()
y_actual_full = y

plt.figure(figsize=(12, 6))
plt.plot(y_actual_full, label='Actual')
plt.plot(y_full_pred, label='Predicted')
plt.title("DNN - Full Carbon Emissions Prediction")
plt.xlabel("Flight Index")
plt.ylabel("Carbon Emissions (kg)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

!pip install stable_baselines3

!pip install "shimmy>=2.0"

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

class CarbonCreditTradingEnv(gym.Env):
    def __init__(self, df):
        super(CarbonCreditTradingEnv, self).__init__()
        self.df = df
        self.current_step = 0
        self.action_space = gym.spaces.Discrete(3)  # 0: Buy, 1: Sell, 2: Hold
        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(len(df.columns),), dtype=np.float32)
        self.balance = 10000
        self.holdings = 0

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.current_step = 0
        self.balance = 10000
        self.holdings = 0
        self.initial_balance = self.balance
        obs = self.df.iloc[self.current_step].values.astype(np.float32)
        return obs, {}

    def step(self, action):
        done = False
        current_data = self.df.iloc[self.current_step]

        buy_price = current_data['credit_cost_usd']
        sell_price = buy_price * (1 + np.random.uniform(-0.05, 0.05))
        number_of_credits = 1

        if action == 0:  # Buy
            if self.balance >= buy_price:
                self.balance -= buy_price
                self.holdings += number_of_credits
        elif action == 1:  # Sell
            if self.holdings > 0:
                self.balance += sell_price
                self.holdings -= number_of_credits

        emissions = current_data['emissions_kg']
        alpha = 0.1  # weight for emissions penalty
        profit = (self.balance + self.holdings * sell_price) - (self.initial_balance + self.holdings * buy_price)

        # Final Reward
        reward = profit - alpha * emissions

        self.current_step += 1
        if self.current_step >= len(self.df) - 1:
            done = True

        obs = self.df.iloc[self.current_step].values.astype(np.float32)
        terminated = done
        truncated = False

        return obs, reward, terminated, truncated, {}

data = flight_data
df = pd.DataFrame(data, columns=['credit_cost_usd', 'emissions_kg', 'credits_needed', 'fuel_burn_kg', 'temperature', 'wind_speed'])

# Wrap environment
env = DummyVecEnv([lambda: CarbonCreditTradingEnv(df)])

# Train PPO Model
model = PPO("MlpPolicy", env, verbose=1, learning_rate=0.001, ent_coef=0.01, n_steps=2048, batch_size=64, n_epochs=100)
model.learn(total_timesteps=10000)

# Simulate Trading
obs = env.reset()
for _ in range(100):
    action, _states = model.predict(obs)
    obs, rewards, done, _, = env.step(action)
    if done:
        break

obs = env.reset()
balance_log = []
emissions_log = []

for step in range(100):
    action, _states = model.predict(obs)
    obs, reward, done, _ = env.step(action)

    # Track emissions and balance
    emissions_log.append(env.envs[0].df.iloc[env.envs[0].current_step]['emissions_kg'])
    balance_log.append(env.envs[0].balance)

    if done:
        break

print(f"Final Balance: ${env.envs[0].balance:.2f}")
print(f"Total Emissions: {sum(emissions_log):.2f} kg")





from stable_baselines3 import A2C
from stable_baselines3.common.vec_env import DummyVecEnv

class CarbonCreditTradingEnv(gym.Env):
    def __init__(self, df):
        super(CarbonCreditTradingEnv, self).__init__()
        self.df = df
        self.current_step = 0
        self.action_space = gym.spaces.Discrete(3)  # 0: Buy, 1: Sell, 2: Hold
        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(len(df.columns),), dtype=np.float32)
        self.balance = 10000
        self.holdings = 0

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.current_step = 0
        self.balance = 10000
        self.holdings = 0
        self.initial_balance = self.balance
        obs = self.df.iloc[self.current_step].values.astype(np.float32)
        return obs, {}

    def step(self, action):
        done = False
        current_data = self.df.iloc[self.current_step]

        buy_price = current_data['credit_cost_usd']
        sell_price = buy_price * (1 + np.random.uniform(-0.05, 0.05))
        number_of_credits = 1

        if action == 0:  # Buy
            if self.balance >= buy_price:
                self.balance -= buy_price
                self.holdings += number_of_credits
        elif action == 1:  # Sell
            if self.holdings > 0:
                self.balance += sell_price
                self.holdings -= number_of_credits

        emissions = current_data['emissions_kg']
        alpha = 0.1  # weight for emissions penalty
        profit = (self.balance + self.holdings * sell_price) - (self.initial_balance + self.holdings * buy_price)

        # Final Reward
        reward = profit - alpha * emissions

        self.current_step += 1
        if self.current_step >= len(self.df) - 1:
            done = True

        obs = self.df.iloc[self.current_step].values.astype(np.float32)
        terminated = done
        truncated = False

        return obs, reward, terminated, truncated, {}

data = flight_data
df = pd.DataFrame(data, columns=['credit_cost_usd', 'emissions_kg', 'credits_needed', 'fuel_burn_kg', 'temperature', 'wind_speed'])

# Wrap environment
env = DummyVecEnv([lambda: CarbonCreditTradingEnv(df)])

# Train PPO Model
model = A2C("MlpPolicy", env, verbose=1, learning_rate=0.001, ent_coef=0.01, n_steps=2048)
model.learn(total_timesteps=10000)

# Simulate Trading
obs = env.reset()
for _ in range(100):
    action, _states = model.predict(obs)
    obs, rewards, done, _, = env.step(action)
    if done:
        break

obs = env.reset()
balance_log = []
emissions_log = []

for step in range(100):
    action, _states = model.predict(obs)
    obs, reward, done, _ = env.step(action)

    # Track emissions and balance
    emissions_log.append(env.envs[0].df.iloc[env.envs[0].current_step]['emissions_kg'])
    balance_log.append(env.envs[0].balance)

    if done:
        break

print(f"Final Balance: ${env.envs[0].balance:.2f}")
print(f"Total Emissions: {sum(emissions_log):.2f} kg")





from stable_baselines3 import SAC
from stable_baselines3.common.vec_env import DummyVecEnv

class CarbonCreditTradingEnv(gym.Env):
    def __init__(self, df):
        super(CarbonCreditTradingEnv, self).__init__()
        self.df = df
        self.current_step = 0
        self.balance = 10000
        self.holdings = 0
        self.total_emissions = 0

        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)
        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(len(df.columns),), dtype=np.float32)

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.current_step = 0
        self.balance = 10000
        self.holdings = 0
        self.total_emissions = 0
        self.initial_balance = self.balance
        obs = self.df.iloc[self.current_step].values.astype(np.float32)
        return obs, {}

    def step(self, action):
        done = False
        current_data = self.df.iloc[self.current_step]

        buy_price = current_data['credit_cost_usd']
        sell_price = buy_price * (1 + np.random.uniform(-0.05, 0.05))
        emissions = current_data['emissions_kg']
        alpha = 0.1

        # Interpret continuous action
        action = action[0]
        if action < -0.33:  # Sell
            if self.holdings > 0:
                self.balance += sell_price
                self.holdings -= 1
        elif action > 0.33:  # Buy
            if self.balance >= buy_price:
                self.balance -= buy_price
                self.holdings += 1

        profit = (self.balance + self.holdings * sell_price) - (self.initial_balance + self.holdings * buy_price)
        reward = profit - alpha * emissions
        self.total_emissions += emissions

        self.current_step += 1
        if self.current_step >= len(self.df) - 1:
            done = True
        terminated = done
        truncated = False

        obs = self.df.iloc[self.current_step].values.astype(np.float32)
        return obs, reward, terminated, truncated, {}

env = DummyVecEnv([lambda: CarbonCreditTradingEnv(df)])

model = SAC("MlpPolicy", env, verbose=1, learning_rate=0.001, train_freq=1)
model.learn(total_timesteps=10000)

obs = env.reset()
emissions_log = []
balance_log = []

for _ in range(100):
    action, _states = model.predict(obs)
    obs, reward, done, _, = env.step(action)

    emissions_log.append(env.envs[0].df.iloc[env.envs[0].current_step]['emissions_kg'])
    balance_log.append(env.envs[0].balance)

    if done:
        break

print(f"Final Balance: {env.envs[0].balance:.2f}")
print(f"Total Emissions: {sum(emissions_log):.2f} kg")

flight_data = flight_data.sort_values(by="callsign")

#Scaling and Preprocessing Data for Emission Prediction Model
features = ['altitude', 'velocity', 'temperature', 'wind_speed', 'humidity', 'distance_km']
target = 'emissions_kg'

scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(flight_data[features])
scaled_target = scaler.fit_transform(flight_data[[target]])

X = []
y = []

n_steps = 3
for i in range(n_steps, len(scaled_features)):
    X.append(scaled_features[i - n_steps:i])
    y.append(scaled_target[i])

X = np.array(X)
y = np.array(y)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, r2_score

# Define features and target
features = ['altitude', 'velocity', 'humidity', 'fuel_burn_kg', 'distance_km', 'wind_speed']
target = 'emissions_kg'

# Scale the features
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(flight_data[features])
y = flight_data[target].values

# Define a sequence length (timesteps for LSTM)
sequence_length = 10

# Prepare sequences for LSTM
X_seq = []
y_seq = []

for i in range(sequence_length, len(X_scaled)):
    X_seq.append(X_scaled[i-sequence_length:i])
    y_seq.append(y[i])

X_seq = np.array(X_seq)  # shape: (samples, timesteps, features)
y_seq = np.array(y_seq)  # shape: (samples,)

# Build the LSTM model
model = Sequential()
model.add(LSTM(64, return_sequences=False, input_shape=(sequence_length, len(features))))
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1))

model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

# Train the model on the full dataset
history = model.fit(X_seq, y_seq, epochs=800, batch_size=64, verbose=1)

# Predict on the full dataset (minus first `sequence_length` entries)
y_pred = model.predict(X_seq).flatten()
y_actual = y_seq

# Evaluate
rmse = np.sqrt(mean_squared_error(y_actual, y_pred))
r2 = r2_score(y_actual, y_pred)

print(f"LSTM RMSE: {rmse:.4f}")
print(f"LSTM RÂ² Score: {r2:.4f}")

# Plot predictions vs actual
plt.figure(figsize=(12, 6))
plt.plot(y_actual, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.title("LSTM - Full Carbon Emissions Prediction")
plt.xlabel("Sample Index")
plt.ylabel("Carbon Emissions (kg)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.tsa.arima.model import ARIMA

def build_lstm_model():
    model = Sequential([
        Input(shape=(X.shape[1],X.shape[2])),
        LSTM(64, return_sequences=True),
        Dropout(0.2),
        LSTM(64),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

# LSTM Forecasting
"""n_seq = len(flight_data) // 10
x_data = flight_data["emissions_kg"].values[:n_seq * 10].reshape(n_seq, 10, 1)
y_data = flight_data["emissions_kg"].values[9:n_seq * 10:10]"""

lstm_model = build_lstm_model()
lstmmodel=lstm_model.fit(X, y.reshape(-1, 1), epochs=800, verbose=0)

predicted = lstm_model.predict(X)
predicted = scaler.inverse_transform(np.concatenate([np.zeros((len(predicted), len(features))), predicted], axis=1))[:, -1]

actual = flight_data[target].values[n_steps:]
plt.figure(figsize=(10,5))
plt.plot(actual, label="Actual")
plt.plot(predicted, label="Predicted")
plt.xlabel('Flight Index')
plt.ylabel('Carbon Emissions (kg)')
plt.legend()
plt.title("LSTM Actual vs Predicted Carbon Emissions")
plt.show()